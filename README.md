# Learning Survival Distributions with Individually Calibrated Asymmetric Laplace Distribution (ICLR 2026)

This repository contains the official implementation of our ICML 2025 paper:

**Learning Survival Distributions with Individually Calibrated Asymmetric Laplace Distribution** ğŸ“„

## ğŸ” Overview
Survival analysis plays a critical role in modeling time-to-event outcomes across various domains. 
Although recent advances have focused on improving *predictive accuracy* and *concordance*, fine-grained *calibration* remains comparatively underexplored. 
In this paper, we propose a survival modeling framework based on the Individually Calibrated Asymmetric Laplace Distribution (ICALD), which unifies *parametric* and *nonparametric* approaches based on the ALD.
We begin by revisiting the probabilistic foundation of the widely used *pinball* loss in *quantile regression* and its reparameterization as the *asymmetry form* of the ALD. 
This reparameterization enables a principled shift to *parametric* modeling while preserving the flexibility of *nonparametric* methods.
Furthermore, we show theoretically that ICALD, with the *quantile regression* loss is probably approximately individually calibrated.
Then we design an extended ICALD framework that supports both *pre-calibration* and *post-calibration* strategies. 
Extensive experiments on 14 synthetic and 7 real-world datasets demonstrate that our method achieves competitive performance in terms of *predictive accuracy*, *concordance*, and *calibration*, while outperforming 12 existing baselines including recent *pre-calibration* and *post-calibration* methods.


## ğŸ—‚ï¸ Directory Structure
```
datasets/
â”œâ”€â”€ breast_msk_2018_clinical_data.tsv   
â”œâ”€â”€ gbsg_cancer_train_test.h5            
â”œâ”€â”€ gbsg.csv                             
â”œâ”€â”€ lgggbm_tcga_pub_clinical_data.tsv    
â”œâ”€â”€ metabric_IHC4_clinical_train_test.h5  
â”œâ”€â”€ support_train_test.h5                
â”œâ”€â”€ tmb_immuno_mskcc.tsv                 
â””â”€â”€ whas_train_test.h5                  # real-world data with real censoring datasets

figures/
â”œâ”€â”€ *.png                               # Figures and visualizations generated during analysis

res/
â”œâ”€â”€ *.json                              # Experiment results

./
â”œâ”€â”€ datasets.py                         # Functions for loading and preprocessing datasets
â”œâ”€â”€ hyperparams.py                      # Hyperparameters used in the experiments 
â”œâ”€â”€ models.py                           # Neural network architectures and custom losses in the experiments 
â”œâ”€â”€ script.py                           # Main script for running experiments
â”œâ”€â”€ utils.py                            # Utility functions for common operations

requirements.txt                        # Python dependencies
README.md                               # Project description and usage instructions
```

---

## **Requirements**
Install the required dependencies using the `requirements.txt` file:
```bash
pip install -r requirements.txt
```

---

## **Usage**

### **1. Data Preparation**
Place all datasets in the `datasets/` folder. Preprocessing functions are available in `datasets.py`.

### **2. Running Experiments**
Use `script.py` to train and evaluate models:
```bash
python script.py
```

### **3. Visualizations**
Figures and plots generated during analysis will be saved in the `figures/` folder.


ğŸ“Œ Note: This paper has been accepted to ICLR 2026. The official proceedings citation will be updated once available.
